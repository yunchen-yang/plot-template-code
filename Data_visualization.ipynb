{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classification evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "def confusion_mat(probs, y):\n",
    "    pred = np.argmax(probs, axis=1)\n",
    "    pred_array = np.zeros((2, 2))\n",
    "    for i in range(len(y)):\n",
    "        pred_array[pred[i], y[i]] += 1\n",
    "    labels = ['Non-cancer', 'Cancer']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=[10,10], squeeze=True)\n",
    "    im = ax.imshow(pred_array, cmap='YlGn')\n",
    "    axins = inset_axes(ax,\n",
    "                   width=\"5%\",\n",
    "                   height=\"50%\",\n",
    "                   loc='lower left',\n",
    "                   bbox_to_anchor=(1.05, 0., 1, 1),\n",
    "                   bbox_transform=ax.transAxes,\n",
    "                   borderpad=0)\n",
    "    plt.colorbar(im, cax=axins)\n",
    "    ax.set_xticks(np.arange(len(labels)))\n",
    "    ax.set_yticks(np.arange(len(labels)))\n",
    "    ax.set_xticklabels(labels, fontsize=25)\n",
    "    ax.set_yticklabels(labels, fontsize=25)\n",
    "    ax.set_ylabel('Predicted labels', fontsize=25)\n",
    "    ax.set_xlabel('True labels', fontsize=25)\n",
    "    ## The code below is only used for new version Matplotlib (verison >= 3.1.1)\n",
    "    bottom, top = ax.get_ylim()\n",
    "    ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "    ####\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            text = ax.text(j, i, pred_array[i, j],\n",
    "                           ha=\"center\", va=\"center\", color=\"k\", fontsize=35)\n",
    "\n",
    "    #fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) ROC analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "def roc(labels, prob):\n",
    "    ## Alway ensure you are assigning the right catagory as positive labels.\n",
    "    y = np.zeros(labels.shape[0])\n",
    "    y[np.where(labels==1)] = 1\n",
    "    ##\n",
    "    fpr, tpr, _ = roc_curve(y, prob[:,1]) # probability of '1'\n",
    "    auc = roc_auc_score(y, prob[:,1])\n",
    "    index = np.argmax(tpr-fpr)\n",
    "    sen = tpr[index]\n",
    "    spe = 1-fpr[index]\n",
    "    return fpr, tpr, auc, sen, spe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_plot(labels, prob):\n",
    "    ## Alway ensure you are assigning the right catagory as positive labels.\n",
    "    y = np.zeros(labels.shape[0])\n",
    "    y[np.where(labels==1)] = 1\n",
    "    ##\n",
    "    fpr, tpr, _ = roc_curve(y, prob[:,1]) # probability of '1'\n",
    "    auc = roc_auc_score(y, prob[:,1])\n",
    "    index = np.argmax(tpr-fpr)\n",
    "    sen = tpr[index]\n",
    "    spe = 1-fpr[index]\n",
    "    fig = plt.figure(figsize=(7,7))\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=2*lw)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([-0.05, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('1 - Specificity', fontsize=25)\n",
    "    plt.ylabel('Sensitivity', fontsize=25)\n",
    "    plt.xticks(fontsize=25)\n",
    "    plt.yticks(fontsize=25)\n",
    "    #plt.title('a vs b', fontsize=25)\n",
    "    plt.text(0.5, 0.3, 'AUC = %0.3f\\nSEN = %0.3f\\nSPE = %0.3f' % (auc, sen, spe), fontsize=20)\n",
    "    #plt.legend(loc=\"lower right\", fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Precision-recall analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "def pr_plot(labels, prob):\n",
    "    ## Alway ensure you are assigning the right catagory as positive labels.\n",
    "    y = np.zeros(labels.shape[0])\n",
    "    y[np.where(labels==1)] = 1\n",
    "    ##\n",
    "    precision, recall, _ = precision_recall_curve(y, prob[:,1]) # probability of '1'\n",
    "    ave_score = average_precision_score(y, prob[:, 1])\n",
    "    \n",
    "    fig = plt.figure(figsize=(7,7))\n",
    "    lw = 2\n",
    "    plt.plot(recall, precision, color='deepskyblue',\n",
    "             lw=lw)\n",
    "    plt.fill_between(recall, min(precision)*np.ones(len(precision)), precision, fc='skyblue', alpha=0.3)\n",
    "    plt.plot([0, 1], [ave_score, ave_score], color='red', lw=1.5*lw, linestyle='--')\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    #plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('Recall', fontsize=25)\n",
    "    plt.ylabel('Precision', fontsize=25)\n",
    "    plt.xticks(fontsize=25)\n",
    "    plt.yticks(fontsize=25)\n",
    "    #plt.title('a vs b', fontsize=25)\n",
    "    plt.legend(labels = ('Precision-recall (PR) curve', 'Average PR score: %0.2f' % ave_score), \n",
    "               loc=\"lower left\", fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
